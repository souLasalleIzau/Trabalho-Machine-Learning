{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratório 4 - Notebook do aluno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visão geral\n",
    "\n",
    "Neste laboratório, você vai preparar um conjunto de dados (dataset) para criar uma previsão (forecast) usando o Amazon Forecast.\n",
    "\n",
    "Este laboratório inclui dois notebooks Jupyter:\n",
    "\n",
    "1. Esse notebook contém as etapas que você seguirá para preparar o conjunto de dados (dataset) e avaliar a previsão (forecast).\n",
    "2. O notebook `forecast-autorun.ipynb` contém as etapas para criar a previsão (forecast) usando o Amazon Forecast. Esse notebook é executado em segundo plano quando o laboratório é iniciado e pode levar entre 1 e 2 horas para ser concluído. Você fará referência a esse notebook durante as etapas do laboratório, mas não precisará executar qualquer célula.\n",
    "\n",
    "\n",
    "## Sobre o conjunto de dados (dataset)\n",
    "\n",
    "Este conjunto de dados (dataset) [Online Retail II] (https://archive.ics.uci.edu/ml/datasets/Online+Retail+II) contém todas as transações que ocorreram entre 12 de janeiro de 2009 e 12 de setembro de 2011 para uma organização de varejo on-line, que não é loja, e que está registrada e localizada no Reino Unido A empresa vende principalmente brindes exclusivos ocasionais. Muitos clientes da empresa são atacadistas.\n",
    "\n",
    "\n",
    "## Informações de atributo\n",
    "\n",
    "- **InvoiceNo** – Número da fatura. Nominal. Um número integral de 6 dígitos atribuído exclusivamente a cada transação. Se esse código começar com a letra *c*, indica um cancelamento.\n",
    "- **StockCode** – Código do produto (item). Nominal. Um número integral de 5 dígitos atribuído exclusivamente a cada produto distinto.\n",
    "- **Description** (Descrição) – Nome do produto (item). Nominal.\n",
    "- **Quantity** (Quantidade) – As quantidades de cada produto (item) por transação. Numérico.\n",
    "- **InvoiceDate** – Data e hora da fatura. Numérico. O dia e a hora em que uma transação foi gerada.\n",
    "- **UnitPrice** – Preço unitário. Numérico. Preço do produto por unidade em libras esterlinas (£).\n",
    "- **CustomerID** – Número do cliente. Nominal. Um número integral de 5 dígitos atribuído exclusivamente a cada cliente.\n",
    "- **Country** (País) – Nome do país. Nominal. O nome do país onde um cliente reside.\n",
    "\n",
    "\n",
    "## Atribuições do conjunto de dados (dataset)\n",
    "\n",
    "Esse conjunto de dados (dataset) foi obtido de:\n",
    "Dua, D. e Graff, C. (2019). repositório UCI Machine Learning (http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruções do laboratório\n",
    "\n",
    "Para concluir esse laboratório, leia e execute as células abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 1: Como importar pacotes Python\n",
    "\n",
    "Comece importando os pacotes necessários do Python.\n",
    "\n",
    "No código a seguir:\n",
    "\n",
    "- *boto3* representa o AWS SDK para Python (Boto3), que é a biblioteca Python da AWS\n",
    "- *pandas* fornece DataFrames para manipular dados de séries temporais\n",
    "- *matplotlib* fornece funções de plotagem\n",
    "- *sagemaker* representa a API necessária para trabalhar com o Amazon SageMaker\n",
    "- *time*,*sys*,*os*,*io* e *json* fornecem funções auxiliares \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "bucket_name='c33334a421003l780155t1w26178775763-forecastbucket-y617mqtzdoyg'\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sagemaker\n",
    "import time, sys, os, io, json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2: Como fazer download e explorar os dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados estão no formato *Microsoft Excel*. O pandas pode ler arquivos do Excel.\n",
    "\n",
    "**Observação:** Esses dados podem levar de 1 a 2 minutos para serem carregados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Excel xlsx file; not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e2924a3a1e1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'online_retail_II.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# files that xlrd can parse don't start with the expected signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'xls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE_FORMAT_DESCRIPTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_format\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'; not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     bk = open_workbook_xls(\n",
      "\u001b[0;31mXLRDError\u001b[0m: Excel xlsx file; not supported"
     ]
    }
   ],
   "source": [
    "retail = pd.read_excel('online_retail_II.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com a descrição do conjunto de dados (dataset), faltam alguns valores. Para simplificar, você removerá qualquer item que estiver com valor ausente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retail' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c2da2bdc297b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'retail' is not defined"
     ]
    }
   ],
   "source": [
    "retail = retail.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comece examinando os dados.\n",
    "\n",
    "Quantas linhas e colunas há no conjunto de dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retail' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e949e8df0d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'retail' is not defined"
     ]
    }
   ],
   "source": [
    "retail.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quais são os tipos de dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retail' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-76d33d55395d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'retail' is not defined"
     ]
    }
   ],
   "source": [
    "retail.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual é a aparência dos dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retail' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1301ff21c258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'retail' is not defined"
     ]
    }
   ],
   "source": [
    "retail.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Amazon Forecast tem esquemas para domínios como, por exemplo, varejo. Revise as informações do esquema em [Domínio do varejo](https://docs.aws.amazon.com/forecast/latest/dg/retail-domain.html) na documentação da AWS.\n",
    "\n",
    "A série temporal de destino são os dados de séries temporais históricos de cada item ou produto vendido pela organização de varejo. Os campos a seguir são obrigatórios:\n",
    "\n",
    "- **item_id** (string) – um identificador exclusivo do item ou do produto do qual você deseja prever a demanda.\n",
    "- **timestamp** (timestamp)\n",
    "- **demand** (float) – o número de vendas desse item no timestamp. Também é o campo de destino para o qual o Amazon Forecast gera uma previsão.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você examinar os dados anteriores, há determinadas colunas que não são necessárias para sua investigação. É possível descartar essas colunas. As colunas que você pode descartar são **Invoice** (Fatura),*Description** (Descrição) e **Customer ID** (ID do Cliente). \n",
    "\n",
    "**Observação:** É possível que os itens na mesma ordem (conforme mostrado na coluna **Invoice** (Fatura)) possam ter uma correlação que afeta o modelo. Para esse laboratório, você ignorará essa possibilidade.\n",
    "\n",
    "Remova as colunas desnecessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retail' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-14aceb5028d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StockCode'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Quantity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Price'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'InvoiceDate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'retail' is not defined"
     ]
    }
   ],
   "source": [
    "retail = retail[['StockCode','Quantity','Price','Country','InvoiceDate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna **InvoiceDate** (Data da fatura) contém seus dados de data e hora. Você pode informar o pandas sobre isso usando a função `to_datetime`. Você pode explorar os dados por tempo, definindo o índice do DataFrame como a coluna **InvoiceDate** (Data da fatura)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail['InvoiceDate'] = pd.to_datetime(retail.InvoiceDate)\n",
    "retail = retail.set_index('InvoiceDate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, você examinará o DataFrame atualizado.\n",
    "\n",
    "O número de linhas e colunas é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os novos dados são semelhantes a este exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que **InvoiceDate** (Data da fatura) é o índice, e é mostrado na primeira coluna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você define o índice para seus dados de data e hora, pode usá-lo para selecionar dados.\n",
    "\n",
    "Para selecionar todas as linhas de uma data específica, use a data no índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail['2010-01-04']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode usar partes de uma data e intervalos de datas. Para visualizar as linhas **Jan** e **Feb** (Fev):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail['2010-01':'2010-02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O intervalo de datas começa em:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.index.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O intervalo de datas termina em:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.index.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o pandas, você pode extrair informações de data facilmente. Você pode extrair informações de data para explorar os dados mais detalhadamente e procurar tendências relacionadas ao tempo.\n",
    "\n",
    "Extraia o ano, o mês e o dia da semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail['Year'] = retail.index.year\n",
    "retail['Month'] = retail.index.month\n",
    "retail['weekday_name'] = retail.index.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados (dataset) que você agora tem inclui compras feitas entre dezembro de 2009 e dezembro de 2010. Podemos dizer que existiria alguma sazonalidade nesses dados. Agora você investigará se há sazonalidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.Month.value_counts(sort=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do gráfico, você pode deduzir alguma sazonalidade:\n",
    "\n",
    "1. Novembro e dezembro parecem ser superiores ao resto do ano.\n",
    "\n",
    "2. T4 parece ser superior que os outros trimestres.\n",
    "\n",
    "3. Para T1, T2 e T3: o último mês do trimestre (meses 3, 6 e 9) parece ter picos.\n",
    "\n",
    "Você observa outros padrões sazonais?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, investigue se há alguma sazonalidade durante a semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "retail.weekday_name.value_counts(sort=False).loc[day_order].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sábado mostra muito poucos pedidos. Por que este pode ser o motivo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 3: Como limpar e reduzir o tamanho dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta tarefa, você reduzirá o tamanho dos dados. Você também removerá quaisquer anomalias, como preços negativos, anomalias (outliers) e dados do país."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução de países\n",
    "Examine os dados do **Country** (País)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.Country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.Country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maioria dos dados parece ser do Reino Unido. Para facilitar o trabalho, filtre os dados por *United Kingdom* (Reino Unido)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_filter = ['United Kingdom']\n",
    "retail = retail[retail.Country.isin(country_filter)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a coluna **Country** (País) contém apenas o mesmo valor, você pode descartá-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail = retail[['StockCode','Quantity','Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como examinar o StockCode e remover anomalias\n",
    "\n",
    "Examine a distribuição da coluna **StockCode** (Código do produto):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.StockCode.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem 4.015 valores exclusivos para **StockCode** (Código do produto). Um gráfico rápido das contagens pode fornecer informações sobre como os valores são distribuídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.StockCode.value_counts().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que há alguns produtos de alta venda, com uma caracteristica de long tail (número grande de vendas, mas em pequenas quantidades) por trás deles. Você pode investigar essa situação com mais detalhes futuramente. No entanto, por enquanto, examine **Quantity** (Quantidade)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.Quantity.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.Quantity.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No gráfico inicial, observe alguns aspectos interessantes.\n",
    "\n",
    "1. Parece haver quantidades negativas.\n",
    "\n",
    "2. Há picos muito grandes ao longo do ano.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As quantidades negativas e zeradas poderão afetar a previsão, se você não souber o motivo da existência desses valores. Para facilitar as coisas por enquanto, você removerá as quantidades negativas e zeradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail = retail[retail.Quantity>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, examine **Price**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.Price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.Price.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico mostra alguns picos claros de preço. Agora, você tentará descobrir o motivo da existência desses picos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail[retail.Price>500].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor **StockCode** (Código do produto) de *M* parece incomum. Se você tiver acesso a um especialista em domínio, poderá saber mais sobre a importância do *M*. Como você não pode solicitar um especialista em domínio para este laboratório, descartará tudo que tiver um valor **StockCode** de *M*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail = retail[retail.StockCode!='M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.Price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse resultado é melhor, mas o valor **max** ainda é alto. Você investigará essa situação em mais detalhes futuramente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail[retail.Price>300].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que ocorreram alguns ajustes. Você também descartará todos os dados que mostram esses ajustes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockcodes = ['ADJUST', 'ADJUST2', 'POST']\n",
    "retail = retail[~retail.StockCode.isin(stockcodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.Price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, você examinará itens com preço zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail[retail.Price==0].count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não há muitos valores nesses resultados, portanto, você pode descartar itens com preço zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail = retail[retail.Price>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados de séries temporais necessários para criar uma previsão exigem um *timestamp*, um *itemId* e um *demand* (demanda). Esses recursos serão mapeados para as colunas **InvoiceDate** (Data da fatura), **StockCode** (Código do produto) e **Quantity** (Quantidade).\n",
    "\n",
    "Os dados relacionados de séries temporais precisam de um *timestamp*, um *itemId* e um *price* (preço). Esses recursos serão mapeados para as colunas **InvoiceDate** (Data da fatura), **StockCode** (Código do produto) e **Price** (Preço).\n",
    "\n",
    "Crie os dois DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = retail[['StockCode','Quantity']]\n",
    "df_related_time_series = retail[['StockCode','Price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora você examinará um único item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series[df_time_series.StockCode==21232]['2009-12-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode ver vários pedidos para cada dia. Você quer criar uma previsão que prevê a demanda em valores totais diários.\n",
    "\n",
    "Você deve *fazer downsample* dos dados dos pedidos individuais em um valor total diário.\n",
    "\n",
    "Os pedidos para cada dia podem ser somados, pois a demanda total para o dia é o valor que você prevê.\n",
    "\n",
    "O pandas fornece a função `resample` para essa finalidade. `sum` somará a coluna **Quantity** (Quantidade). Você também redefinirá o índice com base no valor **InvoiceDate** (Data da fatura). No entanto, desta vez, será uma data sem a parte do tempo.\n",
    "\n",
    "**Observação:** Pode levar até 1 minuto para que esse processo seja concluído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = df_time_series.groupby('StockCode').resample('D').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series['InvoiceDate'] = pd.to_datetime(df_time_series.InvoiceDate)\n",
    "df_time_series = df_time_series.set_index('InvoiceDate')\n",
    "df_time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = df_time_series.groupby('StockCode').resample('D').sum().reset_index().set_index(['InvoiceDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine o novo DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series[df_time_series.StockCode==21232]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O pedido agora tem uma única entrada para cada dia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repita esse processo com os dados de séries temporais relacionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related_time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related_time_series2 = df_related_time_series.groupby('StockCode').resample('D').mean().reset_index().set_index(['InvoiceDate','StockCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related_time_series2.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta:** Por que alguns dos valores anteriores são mostrados como *NaN*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta:** Esse produto não tinha pedidos para esses dias e, portanto, não tem preço. Você deve preencher esses valores NaN com um valor numérico?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail[retail.StockCode == 10002]['2009-12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode usar `pad` para encaminhar o preço. O valor anterior será usado para preencher a lacuna de cada valor ausente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related_time_series3 = df_related_time_series2.groupby('StockCode').pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related_time_series3.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 4: Revisão da criação da previsão\n",
    "\n",
    "As células a seguir são Markdown. Eles demonstram as chamadas de API necessárias para criar uma previsão (forecast) com base nos dados com os quais você está trabalhando. A criação de uma previsão com o Amazon Forecast envolve três estágios:\n",
    "\n",
    "1. Criar os conjuntos de dados (datasets) e importar os dados. Esse processo geralmente leva de 5 a 10 minutos.\n",
    "2. Criação do preditor. Esse processo treina um modelo usando os dados que você forneceu. Leva de 30 a 60 minutos para ser concluído.\n",
    "3. Criação da previsão (forecast). Esse processo gera uma previsão (forecast) para um item específico usando o preditor. Também leva de 30 a 60 minutos para ser concluído.\n",
    "\n",
    "Para economizar tempo, quando esse laboratório foi iniciado, o `forecast-autorun.ipynb` também foi executado em segundo plano. O notebook será atualizado com os resultados após a conclusão da execução. Leva cerca de 65 minutos para ser executado, mas pode demorar um pouco mais. Quando você revisar essa célula, a criação da previsão (forecast) deverá estar em andamento. Quando estiver concluído, você analisará o código.\n",
    "\n",
    "**Observação:** Sinta-se à vontade para revisar o notebook real `forecast-autorun.ipynb`, se quiser mais detalhes. No entanto, certifique-se de não executar nenhuma célula!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de conjuntos de dados (datasets) e importação de dados\n",
    "\n",
    "A primeira etapa é criar um grupo de conjuntos de dados (datasets group) da previsão (forecast):\n",
    "\n",
    "```python\n",
    "session = boto3.Session()\n",
    "forecast = session.client(service_name='forecast') \n",
    "create_dataset_group_response = forecast.create_dataset_group(DatasetGroupName=dataset_group_name, Domain=\"RETAIL\")\n",
    "dataset_group_arn = create_dataset_group_response['DatasetGroupArn']\n",
    "```\n",
    "    \n",
    "A função `create_dataset` requer alguns parâmetros:\n",
    "\n",
    "- **DOMAIN** – este parâmetro especifica o domínio, como *retail* (varejo), que a previsão deve usar.\n",
    "- **DatasetType** – para dados de séries temporais, este parâmetro será definido como* TARGET_TIME_SERIES*.\n",
    "- **DatasetName** – este parâmetro especifica o nome do conjunto de dados.\n",
    "- **DataFrequency** – este parâmetro especifica a frequência. Para o conjunto de dados diário, ele será *D*.\n",
    "- **Schema** (Esquema) – este parâmetro especifica o esquema do conjunto de dados.\n",
    "\n",
    "O esquema do conjunto de dados para os dados de séries temporais é:\n",
    "\n",
    "```python\n",
    "schema ={\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"demand\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "O código para criar o conjunto de dados (dataset) é:\n",
    "\n",
    "```python\n",
    "time_series_response=forecast.create_dataset(\n",
    "                    Domain=\"RETAIL\",\n",
    "                    DatasetType='TARGET_TIME_SERIES',\n",
    "                    DatasetName='retail_time_series_data',\n",
    "                    DataFrequency='D', \n",
    "                    Schema = schema\n",
    ")\n",
    "dataset_arn = time_series_response['DatasetArn']\n",
    "```\n",
    "    \n",
    "Agora que o conjunto de dados está definido, um trabalho é necessário para importar os dados:\n",
    "\n",
    "```python\n",
    "ds_import_job_response=forecast.create_dataset_import_job(DatasetImportJobName='retail_import_job',\n",
    "                                                      DatasetArn=dataset_arn,\n",
    "                                                      DataSource= data_source,\n",
    "                                                      TimestampFormat=timestamp_format\n",
    "                                                     )\n",
    "```\n",
    "\n",
    "Observe que *data_source* é um caminho para os dados armazenados no Amazon Simple Storage Service (Amazon S3).\n",
    "\n",
    "A etapa final é adicionar o conjunto de dados (dataset) ao grupo de conjuntos de dados (datasets group):\n",
    "\n",
    "```python\n",
    "forecast.update_dataset_group(DatasetGroupArn=dataset_group_arn, DatasetArns=[dataset_arn])\n",
    "```\n",
    "    \n",
    "\n",
    "O processo de adição de dados ou metadados relacionados é feito da mesma maneira: alterando os nomes, o esquema e o tipo de conjunto de dados (dataset). Embora tenha preparado esses dados, você não os usará no preditor porque o modelo não foi afetado pelos dados adicionais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do preditor\n",
    "\n",
    "A próxima etapa é criar o preditor. O comando `create_predictor` precisa de alguns parâmetros:\n",
    "\n",
    "- **PredictorName** – este parâmetro especifica o nome que você deseja dar ao preditor.\n",
    "\n",
    "    ```python\n",
    "    predictor_name= prefix+'_deeparp_algo'\n",
    "    ```\n",
    "\n",
    "\n",
    "- **AlgorithmArn** – este parâmetro é o caminho para o algoritmo que você deseja usar. Neste exemplo, você usará o DeepAR +.\n",
    "\n",
    "    ```python\n",
    "    algorithm_arn = 'arn:aws:forecast:::algorithm/Deep_AR_Plus\n",
    "    ```\n",
    "\n",
    "\n",
    "- **EvaluationParameters** – este parâmetro permite que você especifique o número e o tamanho das janelas de backtesting. Lembre-se do módulo de que esse parâmetro controla o tamanho e o número de janelas de teste criadas dos dados.\n",
    "\n",
    "    ```python\n",
    "    evaluation_parameters= {\"NumberOfBacktestWindows\": 1, \"BackTestWindowOffset\": 30}\n",
    "    ```\n",
    "\n",
    "\n",
    "- **ForecastHorizon** – quantas unidades devem ser previstas (neste caso, as unidades são dias).\n",
    "\n",
    "    ```python\n",
    "    forecast_horizon = 30\n",
    "    ```\n",
    "\n",
    "\n",
    "- **InputDataConfig** – este parâmetro especifica os dados, juntamente com dias de férias opcionais.\n",
    "\n",
    "    ```python\n",
    "    input_data_config = {\"DatasetGroupArn\": dataset_group_arn, \"SupplementaryFeatures\": [ {\"Name\": \"holiday\",\"Value\": \"UK\"} ]}\n",
    "    ```\n",
    "\n",
    "\n",
    "- **FeaturizationConfig** – este parâmetro define a frequência, mas também pode ser usado para especificar métodos de preenchimento para dados.\n",
    "\n",
    "    ```python\n",
    "    featurization_config= {\"ForecastFrequency\": dataset_frequency }\n",
    "    ```\n",
    "\n",
    "O código para criar o preditor é:\n",
    "\n",
    "```python\n",
    "create_predictor_response=forecast.create_predictor(PredictorName = predictor_name,\n",
    "      AlgorithmArn = algorithm_arn,\n",
    "      ForecastHorizon = forecast_horizon,\n",
    "      PerformAutoML = False,\n",
    "      PerformHPO = False,\n",
    "      EvaluationParameters= evaluation_parameters, \n",
    "      InputDataConfig = input_data_config,\n",
    "      FeaturizationConfig = featurization_config\n",
    "     )\n",
    "```\n",
    "                                                 \n",
    "Depois que o preditor for criado, você poderá criar uma previsão (forecast)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da previsão (forecast)\n",
    "\n",
    "Para criar a previsão (forecast), use o método `create_forecast`:\n",
    "\n",
    "```python\n",
    "predictor_arn = create_predictor_response['PredictorArn']\n",
    "\n",
    "create_forecast_response=forecast.create_forecast(ForecastName=forecast_Name,\n",
    "                                                  PredictorArn=predictor_arn)\n",
    "\n",
    "```\n",
    "\n",
    "Depois que a previsão (forecast) for gerada, os resultados poderão ser consultados usando o método `query_forecast`:\n",
    "\n",
    "```python\n",
    "forecast_response = forecast_query.query_forecast(\n",
    "    ForecastArn=forecast_arn,\n",
    "    Filters={\"item_id\":\"22423\"}\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 5: Como aguardar a conclusão da criação da previsão (forecast)\n",
    "\n",
    "A previsão (forecast) agora deve ser criada. Você pode investigar para ver se a criação da previsão (forecast) foi concluída.\n",
    "\n",
    "Primeiro, crie um método auxiliar (helper method) para mostrar o status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "class StatusIndicator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.previous_status = None\n",
    "        self.need_newline = False\n",
    "        \n",
    "    def update( self, status ):\n",
    "        if self.previous_status != status:\n",
    "            if self.need_newline:\n",
    "                sys.stdout.write(\"\\n\")\n",
    "            sys.stdout.write( status + \" \")\n",
    "            self.need_newline = True\n",
    "            self.previous_status = status\n",
    "        else:\n",
    "            sys.stdout.write(\".\")\n",
    "            self.need_newline = True\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    def end(self):\n",
    "        if self.need_newline:\n",
    "            sys.stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, crie instâncias da previsão (forecast) e os objetos de consulta da previsão (forecast query objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='c33334a421003l780155t1w26178775763-forecastbucket-y617mqtzdoyg'\n",
    "\n",
    "session = boto3.Session() \n",
    "forecast = session.client(service_name='forecast') \n",
    "forecast_query = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você lerá as variáveis do armazenamento e verificará se a previsão (forecast) foi definida. Depois que a previsão (forecast) for definida, você aguardará até que seu status se torne ativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "    %store -r\n",
    "    is_local = \"forecast_arn\" in locals()\n",
    "    if is_local: break\n",
    "    time.sleep(10)\n",
    "\n",
    "\n",
    "status_indicator = StatusIndicator()\n",
    "while True:\n",
    "    status = forecast.describe_forecast(ForecastArn=forecast_arn)['Status']\n",
    "    status_indicator.update(status)\n",
    "    if status in ('ACTIVE', 'CREATE_FAILED'): break\n",
    "    time.sleep(10)\n",
    "\n",
    "status_indicator.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 6: Usar a previsão (forecast)\n",
    "\n",
    "Neste momento, deve haver uma previsão (forecast) pronta para ser consultada.\n",
    "\n",
    "Verifique se você obtém dados para o seguinte código de estoque de teste: *21232*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "forecast_response = forecast_query.query_forecast(\n",
    "    ForecastArn=forecast_arn,\n",
    "    Filters={\"item_id\":\"21232\"}\n",
    ")\n",
    "print(forecast_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotagem dos resultados reais\n",
    "\n",
    "Anteriormente, você dividiu os dados e reteve os valores de *novembro* e *dezembro*. Você plotará esses valores em relação aos valores previstos para o mesmo período.\n",
    "\n",
    "Você começará lendo os valores de teste de volta em um DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_df = pd.read_csv(test, names=['InvoiceDate','StockCode','Quantity'])\n",
    "actual_df['InvoiceDate'] = pd.to_datetime(actual_df.InvoiceDate)\n",
    "actual_df = actual_df.set_index('InvoiceDate')\n",
    "actual_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique se você tem apenas dados para o código de estoque *21232*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockcode_filter = ['21232']\n",
    "actual_df = actual_df[actual_df['StockCode'].isin(stockcode_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode fazer um gráfico rápido dos dados. Lembre-se de que esses dados são dados de teste, portanto, os valores reais são plotados. Na próxima etapa, você plotará os valores previstos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_df.Quantity.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotagem da previsão\n",
    "\n",
    "Em seguida, você deve converter a resposta JSON do preditor em um DataFrame que possa ser plotado.\n",
    "\n",
    "Comece obtendo as predições P10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate DF \n",
    "prediction_df_p10 = pd.DataFrame.from_dict(forecast_response['Forecast']['Predictions']['p10'])\n",
    "prediction_df_p10.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, plote as predições P10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "prediction_df_p10.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código anterior só recuperou os valores P10 e os colocou em um DataFrame. Agora, conclua o mesmo processo para os valores P50 e P90.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df_p50 = pd.DataFrame.from_dict(forecast_response['Forecast']['Predictions']['p50'])\n",
    "prediction_df_p90 = pd.DataFrame.from_dict(forecast_response['Forecast']['Predictions']['p90'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Comparação da predição com resultados reais\n",
    "\n",
    "Depois de obter os DataFrames, a próxima tarefa é plotá-los juntos para determinar a melhor opção.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by creating a DataFrame to house the content. Here, Source will be which DataFrame it came from.\n",
    "results_df = pd.DataFrame(columns=['timestamp','value','Source'])\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Importe os valores observados para o DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser\n",
    "for index, row in actual_df.iterrows():\n",
    "    #clean_timestamp = dateutil.parser.parse(index)\n",
    "    results_df = results_df.append({'timestamp' : index , 'value' : row['Quantity'], 'Source': 'Actual'} , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the new DataFrame\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add the P10, P50, and P90 Values\n",
    "for index, row in prediction_df_p10.iterrows():\n",
    "    clean_timestamp = dateutil.parser.parse(row['Timestamp'])\n",
    "    results_df = results_df.append({'timestamp' : clean_timestamp , 'value' : row['Value'], 'Source': 'p10'} , ignore_index=True)\n",
    "for index, row in prediction_df_p50.iterrows():\n",
    "    clean_timestamp = dateutil.parser.parse(row['Timestamp'])\n",
    "    results_df = results_df.append({'timestamp' : clean_timestamp , 'value' : row['Value'], 'Source': 'p50'} , ignore_index=True)\n",
    "for index, row in prediction_df_p90.iterrows():\n",
    "    clean_timestamp = dateutil.parser.parse(row['Timestamp'])\n",
    "    results_df = results_df.append({'timestamp' : clean_timestamp , 'value' : row['Value'], 'Source': 'p90'} , ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao criar um pivot nos dados, você pode comparar os valores reais P10, P50 e P90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = results_df.pivot(columns='Source', values='value', index=\"timestamp\")\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os gráficos podem ser mais fáceis de analisar do que os valores brutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como examinar os resultados\n",
    "\n",
    "Possivelmente, no gráfico anterior, você verá pelo menos alguma correlação entre os valores previstos e os valores reais. A correlação pode não ser boa, e pode haver vários motivos para esse resultado:\n",
    "\n",
    "- As vendas são principalmente no atacado, mas incluem alguns pedidos menores.\n",
    "- Você reteve dados, o que significa que uma temporada inteira não foi incluída nos dados de treinamento.\n",
    "- Talvez você tenha perdido a categoria útil ou os dados de promoção de vendas.\n",
    "\n",
    "Como todos os modelos de machine learning, os resultados são tão bons quanto os dados usados para treinar o modelo. Conforme observado anteriormente, o modelo pode ser melhorado com mais dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 7: Limpeza\n",
    "\n",
    "As células a seguir limpam os recursos que foram criados durante o laboratório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.delete_forecast(ForecastArn=forecast_arn)\n",
    "time.sleep(60)\n",
    "\n",
    "forecast.delete_predictor(PredictorArn=predictor_arn)\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.delete_dataset_import_job(DatasetImportJobArn=ds_related_import_job_arn)\n",
    "forecast.delete_dataset_import_job(DatasetImportJobArn=ds_import_job_arn)\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.delete_dataset(DatasetArn=related_dataset_arn)\n",
    "forecast.delete_dataset(DatasetArn=dataset_arn)\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.delete_dataset_group(DatasetGroupArn=dataset_group_arn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
